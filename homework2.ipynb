{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Build a CNN for image recognition.\n",
    "\n",
    "## Due Date:  March 26, 11:59PM\n",
    "\n",
    "### Name: Shadi Ebadi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "1. In this assignment, you will build Convolutional Neural Network to classify CIFAR-10 Images.\n",
    "2. You can directly load dataset from many deep learning packages.\n",
    "3. You can use any deep learning packages such as pytorch, keras or tensorflow for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements:\n",
    "\n",
    "1. You need to load cifar 10 data and split the entire training dataset into training and validation.\n",
    "2. You will implement a CNN model to classify cifar 10 images with provided structure.\n",
    "3. You need to plot the training and validation accuracy or loss obtained from above step.\n",
    "4. Then you can use tuned parameters to train using the entire training dataset.\n",
    "5. You should report the testing accuracy using the model with complete data.\n",
    "6. You may try to change the structure (e.g, add BN layer or dropout layer,...) and analyze your findings.\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Batch Normalization is a technique to speed up training and help make the model more stable.\n",
    "- In simple words, batch normalization is just another network layer that gets inserted between a hidden layer and the next hidden layer. Its job is to take the outputs from the first hidden layer and normalize them before passing them on as the input of the next hidden layer.\n",
    "\n",
    "- For more detailed information, you may refer to the original paper: https://arxiv.org/pdf/1502.03167.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: Values of $x$ over a mini-batch: $\\mathbf{B}$ = $\\{x_1,..., x_m\\};$\n",
    "- Output: $\\{y_i = BN_{\\gamma,\\beta}(x_i)\\}$, $\\gamma, \\beta$ are learnable parameters\n",
    "\n",
    "Normalization of the Input:\n",
    "$$\\mu_{\\mathbf{B}} = \\frac{1}{m}\\sum_{i=1}^m x_i$$\n",
    "$$\\sigma_{\\mathbf{B}}^2 = \\frac{1}{m}\\sum_{i=1}^m (x_i - \\mu_{\\mathbf{B}})^2$$\n",
    "$$\\hat{x_i} = \\frac{x_i - \\mu_{\\mathbf{B}}}{\\sqrt{\\sigma_{\\mathbf{B}}}^2 + \\epsilon}$$\n",
    "Re-scaling and Offsetting:\n",
    "$$y_i = \\gamma \\hat{x_i} + \\beta = BN_{\\gamma,\\beta}(x_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of BN:\n",
    "1. Improves gradient flow through the network.\n",
    "2. Allows use of saturating nonlinearities and higher learning rates.\n",
    "3. Makes weights easier to initialize.\n",
    "4. Act as a form of regularization and may reduce the need for dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "- The location of BN layer: Please make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: keras==2.12 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow==2.12) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.13.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (16.0.6)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (4.25.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (58.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (4.11.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\sheba\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12) (0.37.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (4.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sheba\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.12 keras==2.12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\sheba\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import h5py  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 5s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Load Cifar-10 Data\n",
    "# This is just an example, you may load dataset from other packages.\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "# If you can not load keras dataset, un-comment these two lines.\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels (5 points)\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Implement a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    a=y.shape[0]\n",
    "    \n",
    "    zero_matrix =np.zeros((a,num_class)) \n",
    "    \n",
    "    for i in range(a):\n",
    "        j=y[i]\n",
    "\n",
    "        zero_matrix[i,j]=1\n",
    "        \n",
    "        \n",
    "    return zero_matrix\n",
    "    \n",
    "\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets (5 points)\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets: \n",
    "* a training set containing 40K samples: x_tr, y_tr\n",
    "* a validation set containing 10K samples: x_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Shape of y_train_vec: ' + str(x_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_valid_vec: (10000, 32, 32, 3)\n",
      "Shape of y_valid_vec: (10000, 10)\n",
      "Shape of x_train_vec: (40000, 32, 32, 3)\n",
      "Shape of y_train_vec: (40000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Generate  random  indices\n",
    "rand_indices = np.random.permutation(50000)\n",
    "\n",
    "# Splitting indices into training and validation sets\n",
    "train_indices = rand_indices[0:40000]  #  40,000 for training\n",
    "valid_indices = rand_indices[40000:] #  10,000 for validation\n",
    "\n",
    "# Create validation data\n",
    "x_valid_vec = x_train[valid_indices, :, :, :] \n",
    "y_valid_vec = y_train_vec[valid_indices, :]\n",
    "\n",
    "# Create training data\n",
    "x_train_vec = x_train[train_indices, :, :, :]\n",
    "y_train_vec = y_train_vec[train_indices, :]\n",
    "\n",
    "#  Print the shapes of the resulting sets\n",
    "print('Shape of x_valid_vec:', x_valid_vec.shape)\n",
    "print('Shape of y_valid_vec:', y_valid_vec.shape)\n",
    "print('Shape of x_train_vec:', x_train_vec.shape)\n",
    "print('Shape of y_train_vec:', y_train_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters (50 points)\n",
    "\n",
    "- Build a convolutional neural network model using the below structure:\n",
    "\n",
    "- It should have a structure of: Conv - ReLU - Max Pool - ConV - ReLU - Max Pool - Dense - ReLU - Dense - Softmax\n",
    "\n",
    "- In the graph 3@32x32 means the dimension of input image, 32@30x30 means it has 32 filters and the dimension now becomes 30x30 after the convolution.\n",
    "- All convolutional layers (Conv) should have stride = 1 and no padding.\n",
    "- Max Pooling has a pool size of 2 by 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You may use the validation data to tune the hyper-parameters (e.g., learning rate, and optimization algorithm)\n",
    "- Do NOT use test data for hyper-parameter tuning!!!\n",
    "- Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(64, (4,4), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model optimizer and loss function\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.0001) \n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 37s 114ms/step - loss: 4.3361 - accuracy: 0.2684 - val_loss: 1.9172 - val_accuracy: 0.3705\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 37s 117ms/step - loss: 1.6303 - accuracy: 0.4374 - val_loss: 1.5300 - val_accuracy: 0.4687\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 1.3402 - accuracy: 0.5330 - val_loss: 1.4131 - val_accuracy: 0.5105\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 36s 115ms/step - loss: 1.1661 - accuracy: 0.5962 - val_loss: 1.4264 - val_accuracy: 0.5265\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 1.0350 - accuracy: 0.6414 - val_loss: 1.3559 - val_accuracy: 0.5436\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.9284 - accuracy: 0.6820 - val_loss: 1.2664 - val_accuracy: 0.5789\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.8322 - accuracy: 0.7142 - val_loss: 1.2688 - val_accuracy: 0.5824\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.7427 - accuracy: 0.7490 - val_loss: 1.3071 - val_accuracy: 0.5812\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 0.6629 - accuracy: 0.7753 - val_loss: 1.2724 - val_accuracy: 0.6002\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5942 - accuracy: 0.8016 - val_loss: 1.2626 - val_accuracy: 0.6017\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.5281 - accuracy: 0.8256 - val_loss: 1.3097 - val_accuracy: 0.6055\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 36s 114ms/step - loss: 0.4661 - accuracy: 0.8470 - val_loss: 1.3200 - val_accuracy: 0.6105\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.4109 - accuracy: 0.8676 - val_loss: 1.3370 - val_accuracy: 0.6165\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 37s 120ms/step - loss: 0.3585 - accuracy: 0.8876 - val_loss: 1.4353 - val_accuracy: 0.6036\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 34s 110ms/step - loss: 0.3122 - accuracy: 0.9040 - val_loss: 1.4463 - val_accuracy: 0.6070\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 35s 113ms/step - loss: 0.2712 - accuracy: 0.9178 - val_loss: 1.5519 - val_accuracy: 0.5982\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 0.2320 - accuracy: 0.9320 - val_loss: 1.6206 - val_accuracy: 0.6023\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 40s 127ms/step - loss: 0.1972 - accuracy: 0.9455 - val_loss: 1.6459 - val_accuracy: 0.6023\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 43s 137ms/step - loss: 0.1682 - accuracy: 0.9549 - val_loss: 1.6381 - val_accuracy: 0.6132\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 42s 136ms/step - loss: 0.1398 - accuracy: 0.9636 - val_loss: 1.7234 - val_accuracy: 0.6131\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 0.1184 - accuracy: 0.9706 - val_loss: 1.7443 - val_accuracy: 0.6225\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 0.0975 - accuracy: 0.9770 - val_loss: 1.8305 - val_accuracy: 0.6198\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0821 - accuracy: 0.9810 - val_loss: 1.9256 - val_accuracy: 0.6158\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0683 - accuracy: 0.9851 - val_loss: 1.9448 - val_accuracy: 0.6216\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.0576 - accuracy: 0.9879 - val_loss: 1.9874 - val_accuracy: 0.6294\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 45s 143ms/step - loss: 0.0486 - accuracy: 0.9896 - val_loss: 2.2345 - val_accuracy: 0.6085\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 46s 146ms/step - loss: 0.0409 - accuracy: 0.9919 - val_loss: 2.3162 - val_accuracy: 0.5980\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0347 - accuracy: 0.9937 - val_loss: 2.2299 - val_accuracy: 0.6182\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 47s 150ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 2.3811 - val_accuracy: 0.6101\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 45s 142ms/step - loss: 0.0265 - accuracy: 0.9948 - val_loss: 2.4668 - val_accuracy: 0.6113\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0248 - accuracy: 0.9948 - val_loss: 2.4294 - val_accuracy: 0.6136\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 2.3581 - val_accuracy: 0.6325\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0211 - accuracy: 0.9954 - val_loss: 2.4235 - val_accuracy: 0.6287\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 2.4560 - val_accuracy: 0.6227\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 45s 145ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 2.5550 - val_accuracy: 0.6321\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0167 - accuracy: 0.9963 - val_loss: 2.9406 - val_accuracy: 0.6056\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 2.7632 - val_accuracy: 0.6190\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 42s 135ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 2.7812 - val_accuracy: 0.6282\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 2.6697 - val_accuracy: 0.6325\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 2.7278 - val_accuracy: 0.6324\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 44s 140ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 2.7958 - val_accuracy: 0.6338\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 47s 149ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 2.8456 - val_accuracy: 0.6276\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 43s 136ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 3.0057 - val_accuracy: 0.6213\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 44s 141ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 2.8652 - val_accuracy: 0.6312\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 3.2588 - val_accuracy: 0.6178\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 3.1646 - val_accuracy: 0.6225\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 46s 148ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 3.1797 - val_accuracy: 0.6209\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 43s 139ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 3.1114 - val_accuracy: 0.6284\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 44s 142ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 3.0579 - val_accuracy: 0.6380\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 3.1255 - val_accuracy: 0.6354\n"
     ]
    }
   ],
   "source": [
    "# Train the model and store model parameters/loss values\n",
    "history = model.fit(x_train_vec, y_train_vec, batch_size=128, epochs=50, validation_data=(x_valid_vec, y_valid_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and validation loss curve versus epochs. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "epochs = range(50)  \n",
    "train_acc = history.history['loss']\n",
    "valid_acc = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_acc, 'bo', label='Training loss')\n",
    "plt.plot(epochs, valid_acc, 'r', label='Validation loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a function for the cnn model  and used it in loop for finding the best hyperparameters\n",
    "(learning rate and optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(optimizer, learning_rate):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(64, (4,4), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "   \n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(x_train_vec, y_train_vec, epochs=5, validation_data=(x_valid_vec, y_valid_vec), verbose=0)\n",
    "\n",
    "    return history.history['val_accuracy'][-1] \n",
    "                           \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  \n",
    "optimizers = [keras.optimizers.Adam, keras.optimizers.SGD, keras.optimizers.RMSprop]\n",
    "learning_rates = [0.001, 0.0005, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'optimizer': <class 'keras.optimizers.legacy.adam.Adam'>, 'learning_rate': 0.0005}, Best Accuracy: 0.6236\n"
     ]
    }
   ],
   "source": [
    "best_accuracy=0\n",
    "best_param={}\n",
    "\n",
    "for i in optimizers:\n",
    "    for j in learning_rates:\n",
    "        accuracy=build_model(i, j)\n",
    "        \n",
    "        if accuracy>best_accuracy:\n",
    "            best_accuracy=accuracy\n",
    "            best_param={'optimizer': i, 'learning_rate': j}\n",
    "            \n",
    "print(f\"\\nBest Hyperparameters: {best_param}, Best Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train (again) and evaluate the model (5 points)\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 52s 129ms/step - loss: 0.7503 - accuracy: 0.8014\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.4194 - accuracy: 0.8686\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 48s 122ms/step - loss: 0.2881 - accuracy: 0.9049\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 47s 120ms/step - loss: 0.2362 - accuracy: 0.9201\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.1967 - accuracy: 0.9339\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 48s 123ms/step - loss: 0.1842 - accuracy: 0.9374\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.1543 - accuracy: 0.9481\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 48s 122ms/step - loss: 0.1438 - accuracy: 0.9509\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.1408 - accuracy: 0.9536\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 50s 128ms/step - loss: 0.1162 - accuracy: 0.9610\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 51s 130ms/step - loss: 0.1320 - accuracy: 0.9559\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 48s 121ms/step - loss: 0.0962 - accuracy: 0.9681\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 50s 129ms/step - loss: 0.1214 - accuracy: 0.9601\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.1203 - accuracy: 0.9606\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 40s 102ms/step - loss: 0.0946 - accuracy: 0.9690\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 0.0938 - accuracy: 0.9686\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 0.0911 - accuracy: 0.9702\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.0886 - accuracy: 0.9705\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 37s 96ms/step - loss: 0.0898 - accuracy: 0.9712\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 37s 95ms/step - loss: 0.0799 - accuracy: 0.9735\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.0849 - accuracy: 0.9718\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 38s 97ms/step - loss: 0.0732 - accuracy: 0.9769\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 0.0938 - accuracy: 0.9713\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 40s 102ms/step - loss: 0.0759 - accuracy: 0.9763\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 41s 104ms/step - loss: 0.0612 - accuracy: 0.9798\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 39s 100ms/step - loss: 0.0818 - accuracy: 0.9743\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 42s 108ms/step - loss: 0.0666 - accuracy: 0.9786\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 41s 104ms/step - loss: 0.0843 - accuracy: 0.9740\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 42s 107ms/step - loss: 0.0729 - accuracy: 0.9782\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 41s 104ms/step - loss: 0.0667 - accuracy: 0.9793\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 0.0443 - accuracy: 0.9860\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 38s 96ms/step - loss: 0.0609 - accuracy: 0.9813\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 39s 99ms/step - loss: 0.0716 - accuracy: 0.9787\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 40s 101ms/step - loss: 0.0760 - accuracy: 0.9776\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 40s 102ms/step - loss: 0.0763 - accuracy: 0.9776\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 42s 108ms/step - loss: 0.0553 - accuracy: 0.9834\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 42s 106ms/step - loss: 0.0541 - accuracy: 0.9841\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 43s 110ms/step - loss: 0.0749 - accuracy: 0.9787\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 42s 106ms/step - loss: 0.0648 - accuracy: 0.9813\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 42s 108ms/step - loss: 0.0497 - accuracy: 0.9858\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 42s 109ms/step - loss: 0.0528 - accuracy: 0.9845\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 41s 105ms/step - loss: 0.0516 - accuracy: 0.9843\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 41s 106ms/step - loss: 0.0410 - accuracy: 0.9883\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 41s 106ms/step - loss: 0.0567 - accuracy: 0.9842\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 41s 105ms/step - loss: 0.0585 - accuracy: 0.9839\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 42s 107ms/step - loss: 0.0505 - accuracy: 0.9853\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 42s 107ms/step - loss: 0.0481 - accuracy: 0.9872\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 41s 106ms/step - loss: 0.0726 - accuracy: 0.9803\n"
     ]
    }
   ],
   "source": [
    "#<Compile your model again (using the same hyper-parameters you tuned above)>\n",
    "#<Train your model on the entire training set (50K samples)>\n",
    "\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_train_vec_1 = to_one_hot(y_train)\n",
    "\n",
    "history = model.fit(x_train, y_train_vec_1, batch_size=128, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the model on the test set (5 points)\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 6s - loss: 1.8627e-04 - accuracy: 1.0000 - 6s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluating  model performance  on testing data.\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_test_vec_1 = to_one_hot(y_test)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_vec_1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Building model with new structure (25 points)\n",
    "- In this section, you can build your model with adding new layers (e.g, BN layer or dropout layer, ...)\n",
    "- If you want to regularize a ```Conv/Dense layer```, you should place a ```Dropout layer``` before the ```Conv/Dense layer```.\n",
    "- You can try to compare their loss curve and testing accuracy and analyze your findings.\n",
    "- You need to try at lease two different structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch normalization layer has already been implemented in many packages. You may simply call the function to build the layer. For example: torch.nn.BatchNorm2d() using pytroch package, keras.layers.BatchNormalization() using keras package.\n",
    "The location of BN layer: Please make sure BatchNormalization is between a Conv/Dense layer and an activation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 76s 189ms/step - loss: 1.5915 - accuracy: 0.4297\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.2201 - accuracy: 0.5621\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 74s 188ms/step - loss: 1.0733 - accuracy: 0.6198\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 72s 183ms/step - loss: 0.9851 - accuracy: 0.6534\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.9189 - accuracy: 0.6773\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.8652 - accuracy: 0.6947\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.8224 - accuracy: 0.7102\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 71s 183ms/step - loss: 0.7816 - accuracy: 0.7242\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.7463 - accuracy: 0.7377\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 73s 188ms/step - loss: 0.7161 - accuracy: 0.7486\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.6814 - accuracy: 0.7619\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 78s 200ms/step - loss: 0.6622 - accuracy: 0.7662\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6308 - accuracy: 0.7786\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.6135 - accuracy: 0.7843\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.5914 - accuracy: 0.7896\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 74s 190ms/step - loss: 0.5753 - accuracy: 0.7979\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 74s 189ms/step - loss: 0.5589 - accuracy: 0.8031\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 74s 189ms/step - loss: 0.5402 - accuracy: 0.8090\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.5249 - accuracy: 0.8162\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 71s 181ms/step - loss: 0.5097 - accuracy: 0.8216\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.4904 - accuracy: 0.8245\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.4800 - accuracy: 0.8312\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.4644 - accuracy: 0.8372\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 76s 195ms/step - loss: 0.4502 - accuracy: 0.8417\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 77s 196ms/step - loss: 0.4361 - accuracy: 0.8463\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 77s 198ms/step - loss: 0.4247 - accuracy: 0.8505\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 74s 190ms/step - loss: 0.4107 - accuracy: 0.8541\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 76s 195ms/step - loss: 0.4005 - accuracy: 0.8568\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 74s 190ms/step - loss: 0.3886 - accuracy: 0.8626\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 74s 189ms/step - loss: 0.3723 - accuracy: 0.8685\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.3689 - accuracy: 0.8688\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.3602 - accuracy: 0.8711\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.3469 - accuracy: 0.8763\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 74s 189ms/step - loss: 0.3366 - accuracy: 0.8802\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 73s 188ms/step - loss: 0.3291 - accuracy: 0.8822\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.3256 - accuracy: 0.8835\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 71s 183ms/step - loss: 0.3147 - accuracy: 0.8872\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 77s 196ms/step - loss: 0.3064 - accuracy: 0.8904\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 73s 188ms/step - loss: 0.2971 - accuracy: 0.8936\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 79s 202ms/step - loss: 0.2969 - accuracy: 0.8937\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 78s 200ms/step - loss: 0.2885 - accuracy: 0.8980\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 83s 211ms/step - loss: 0.2757 - accuracy: 0.9033\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.2767 - accuracy: 0.9005\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.2717 - accuracy: 0.9029\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 70s 179ms/step - loss: 0.2570 - accuracy: 0.9092\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 70s 180ms/step - loss: 0.2581 - accuracy: 0.9074\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.2529 - accuracy: 0.9092\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 0.2460 - accuracy: 0.9119\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.2440 - accuracy: 0.9132\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 86s 219ms/step - loss: 0.2372 - accuracy: 0.9154\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Build the model\n",
    "model_1 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation=None, input_shape=(32,32,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (4,4), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_1.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Convert y_train to one-hot encoding\n",
    "y_train_vec_1 = to_one_hot(y_train)\n",
    "\n",
    "# Train the model\n",
    "history_1 = model_1.fit(x_train, y_train_vec_1, batch_size=128, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 7s - loss: 0.8775 - accuracy: 0.7557 - 7s/epoch - 22ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluating  model performance  on testing data.\n",
    "model_1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_test_vec_1 = to_one_hot(y_test)\n",
    "\n",
    "test_loss, test_acc = model_1.evaluate(x_test, y_test_vec_1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 1.3589 - accuracy: 0.5175\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.9875 - accuracy: 0.6527\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.8493 - accuracy: 0.7022\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.7563 - accuracy: 0.7380\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.6806 - accuracy: 0.7646\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.6118 - accuracy: 0.7860\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 59s 150ms/step - loss: 0.5629 - accuracy: 0.8046\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 58s 150ms/step - loss: 0.5105 - accuracy: 0.8227\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.4571 - accuracy: 0.8411\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.4125 - accuracy: 0.8569\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.3724 - accuracy: 0.8712\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 58s 149ms/step - loss: 0.3323 - accuracy: 0.8866\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.2931 - accuracy: 0.9007\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 58s 148ms/step - loss: 0.2614 - accuracy: 0.9132\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 58s 148ms/step - loss: 0.2244 - accuracy: 0.9254\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.2004 - accuracy: 0.9330\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 58s 149ms/step - loss: 0.1678 - accuracy: 0.9471\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.1476 - accuracy: 0.9536\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.1370 - accuracy: 0.9572\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.1142 - accuracy: 0.9657\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0913 - accuracy: 0.9743\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 58s 148ms/step - loss: 0.0871 - accuracy: 0.9752\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0744 - accuracy: 0.9791\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.0785 - accuracy: 0.9763\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 62s 157ms/step - loss: 0.0775 - accuracy: 0.9757\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 65s 165ms/step - loss: 0.0582 - accuracy: 0.9839\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 63s 162ms/step - loss: 0.0642 - accuracy: 0.9809\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 63s 160ms/step - loss: 0.0546 - accuracy: 0.9844\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 63s 161ms/step - loss: 0.0389 - accuracy: 0.9901\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 60s 154ms/step - loss: 0.0506 - accuracy: 0.9841\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 58s 148ms/step - loss: 0.0645 - accuracy: 0.9789\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0420 - accuracy: 0.9871\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.0293 - accuracy: 0.9929\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0398 - accuracy: 0.9878\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 61s 156ms/step - loss: 0.0704 - accuracy: 0.9760\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 63s 160ms/step - loss: 0.0263 - accuracy: 0.9930\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 61s 157ms/step - loss: 0.0147 - accuracy: 0.9970\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 61s 155ms/step - loss: 0.0530 - accuracy: 0.9823\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 60s 153ms/step - loss: 0.0517 - accuracy: 0.9830\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0314 - accuracy: 0.9903\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0099 - accuracy: 0.9983\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0058 - accuracy: 0.9995\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 57s 147ms/step - loss: 0.0565 - accuracy: 0.9811\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.0766 - accuracy: 0.9732\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0186 - accuracy: 0.9948\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 57s 146ms/step - loss: 0.0063 - accuracy: 0.9992\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 58s 148ms/step - loss: 0.0036 - accuracy: 0.9999\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 59s 151ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 58s 149ms/step - loss: 0.0902 - accuracy: 0.9716\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 57s 145ms/step - loss: 0.0634 - accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Build the model\n",
    "model_2 = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation=None, input_shape=(32,32,3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (4,4), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(optimizer=Adam(learning_rate=0.0005),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "\n",
    "# Convert y_train to one-hot encoding\n",
    "y_train_vec_1 = to_one_hot(y_train)\n",
    "\n",
    "# Train the model\n",
    "history_2 = model_2.fit(x_train, y_train_vec_1, batch_size=128, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 8s - loss: 1.7881 - accuracy: 0.7152 - 8s/epoch - 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model performance on testing data.\n",
    "model_2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y_test_vec_1 = to_one_hot(y_test)\n",
    "\n",
    "test_loss_2, test_acc_2 = model_2.evaluate(x_test, y_test_vec_1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the loss curve\n",
    "\n",
    "\n",
    "# Extract loss values\n",
    "epochs = range(50) \n",
    "\n",
    "train_loss_1 = history_1.history['loss']\n",
    "train_loss_2 = history_2.history['loss']\n",
    "\n",
    "# Plot training loss for both structures\n",
    "plt.plot(epochs, train_loss_1, 'bo-', label='Loss for structure 1')\n",
    "plt.plot(epochs, train_loss_2, 'ro-', label='Loss for structure 2')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Comparison')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure 2 has better regularization. ( only using BN and not drop out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
